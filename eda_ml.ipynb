{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview from Orem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 pts supervised learning\n",
    "\n",
    "* feature engineering / selection, bivariate charts? Interactions?\n",
    "* missing data? how to handle it?\n",
    "* Selection of modeling algorithm? classification or regression? binary or multi-class?  \n",
    "* interpretation of variable importance, coefficients if applicable\n",
    "* justification of choice of metric (accuracy, precision / recall, other?)\n",
    "* is class weighting or over / under sampling appropriate?\n",
    "* discussion of choice or tuning of hyperparameters, if any\n",
    "* meaningful discussion of predictive power and conclusions from model\n",
    "* look at misclassified examples from test dataset, what do they say about your model?\n",
    "* outliers in data?\n",
    "\n",
    "10 pts unsupervised learning\n",
    "\n",
    "* take a look at PCA, percent explained\n",
    "* take a look at top eigenvector or two, what is it made out of?\n",
    "* can you visualize your prediciton problem projecting to 2 dimensions?\n",
    "* try k-means clustering. how do you want to select k?\n",
    "* can you cluster your data and visualize on 2 dimensions?\n",
    "* Can you meaningfully identify the cluster groups?\n",
    "\n",
    "? pts PCA\n",
    "\n",
    "* analysis and interpretation of factor loadings\n",
    "* discussion of scree plot and/or analysis of some density plots of PCs\n",
    "* meaningful interpretation / discussion of conclusions \n",
    "\n",
    "? pts k-means\n",
    "\n",
    "* discussion for choosing number of clusters\n",
    "* analysis of cluster centers\n",
    "* bivariate chart(s) against meaningful variables and/or analysis of density plots\n",
    "* meaningful interpretation / discussion of conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haleigh preliminary work 4/10/24:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned from inspection.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"clean_speeddating_with_na.csv\", low_memory=False)\n",
    "\n",
    "#convert all objects data types (which are all the binned columns) to str for vectorizing later\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == 'object':\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "df.dtypes #the code did nothing, maybe I'm misunderstanding what an object data type is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature selection/first look at correlations with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)\n",
    "\n",
    "y=df['match']\n",
    "X=df.loc[:, df.columns != 'match'] #first look at all features. can select some later\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find which columns are strings or objects (will vectorize these)\n",
    "str_cols = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype != 'int64' and df[col].dtype != 'float64':\n",
    "        str_cols.append(col)\n",
    "\n",
    "str_cols #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'has_null',\n",
       " 'wave',\n",
       " 'age',\n",
       " 'age_o',\n",
       " 'd_age',\n",
       " 'samerace',\n",
       " 'importance_same_race',\n",
       " 'importance_same_religion',\n",
       " 'pref_o_attractive',\n",
       " 'pref_o_sincere',\n",
       " 'pref_o_intelligence',\n",
       " 'pref_o_funny',\n",
       " 'pref_o_ambitious',\n",
       " 'pref_o_shared_interests',\n",
       " 'attractive_o',\n",
       " 'sinsere_o',\n",
       " 'intelligence_o',\n",
       " 'funny_o',\n",
       " 'ambitous_o',\n",
       " 'shared_interests_o',\n",
       " 'attractive_important',\n",
       " 'sincere_important',\n",
       " 'intellicence_important',\n",
       " 'funny_important',\n",
       " 'ambtition_important',\n",
       " 'shared_interests_important',\n",
       " 'attractive',\n",
       " 'sincere',\n",
       " 'intelligence',\n",
       " 'funny',\n",
       " 'ambition',\n",
       " 'attractive_partner',\n",
       " 'sincere_partner',\n",
       " 'intelligence_partner',\n",
       " 'funny_partner',\n",
       " 'ambition_partner',\n",
       " 'shared_interests_partner',\n",
       " 'sports',\n",
       " 'tvsports',\n",
       " 'exercise',\n",
       " 'dining',\n",
       " 'museums',\n",
       " 'art',\n",
       " 'hiking',\n",
       " 'gaming',\n",
       " 'clubbing',\n",
       " 'reading',\n",
       " 'tv',\n",
       " 'theater',\n",
       " 'movies',\n",
       " 'concerts',\n",
       " 'music',\n",
       " 'shopping',\n",
       " 'yoga',\n",
       " 'interests_correlate',\n",
       " 'expected_happy_with_sd_people',\n",
       " 'expected_num_interested_in_me',\n",
       " 'expected_num_matches',\n",
       " 'like',\n",
       " 'guess_prob_liked',\n",
       " 'met',\n",
       " 'decision',\n",
       " 'decision_o',\n",
       " 'match']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of all other columns\n",
    "int_cols = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'int64' or df[col].dtype == 'float64':\n",
    "        int_cols.append(col)\n",
    "\n",
    "int_cols #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (59, 59), indices imply (6283, 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m,\n\u001b[1;32m      3\u001b[0m                              stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m vectorized_str \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X_train[str_cols])\n\u001b[0;32m----> 5\u001b[0m vectorized_str \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(vectorized_str\u001b[38;5;241m.\u001b[39mtoarray(), columns \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out(), \n\u001b[1;32m      6\u001b[0m                                index \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      7\u001b[0m X_train_mg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(vectorized_str, int_cols, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m X_train_mg\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    747\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    748\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    749\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    756\u001b[0m         )\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    759\u001b[0m             data,\n\u001b[1;32m    760\u001b[0m             index,\n\u001b[1;32m    761\u001b[0m             columns,\n\u001b[1;32m    762\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    763\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    764\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    765\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    333\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    334\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    407\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (59, 59), indices imply (6283, 59)"
     ]
    }
   ],
   "source": [
    "#vectorize all the string columns then merge result with the rest of the columns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.90,\n",
    "                             stop_words='english')\n",
    "vectorized_str = vectorizer.fit_transform(X_train[str_cols])\n",
    "vectorized_str = pd.DataFrame(vectorized_str.toarray(), columns = vectorizer.get_feature_names_out(), \n",
    "                               index = X_train.index)\n",
    "X_train_mg = pd.merge(vectorized_str, int_cols, left_index=True, right_index=True)\n",
    "X_train_mg.head()\n",
    "\n",
    "#error: Shape of passed values is (59, 59), indices imply (6283, 59) on line: vectorized_str = pd.DataFrame(vectorized_str.toarray(), columns = vectorizer.get_feature_names_out(), index = X_train.index)\n",
    "#what happened to all my rows?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
